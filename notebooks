{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industrial Defect Detection CNN - Model Exploration\n",
    "\n",
    "This notebook explores the implementation of a CNN-based system for detecting manufacturing defects. We'll use the MVTec Anomaly Detection dataset for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths to the MVTec dataset\n",
    "# You need to download and extract the dataset first\n",
    "BASE_DIR = \"mvtec_anomaly_detection\"\n",
    "CATEGORY = \"bottle\"  # You can change this to explore different categories\n",
    "\n",
    "# Check available categories\n",
    "if os.path.exists(BASE_DIR):\n",
    "    categories = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))]\n",
    "    print(f\"Available categories: {categories}\")\n",
    "else:\n",
    "    print(f\"Dataset directory '{BASE_DIR}' not found. Please download the MVTec dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Let's explore the structure of a specific category\n",
    "category_dir = os.path.join(BASE_DIR, CATEGORY)\n",
    "if os.path.exists(category_dir):\n",
    "    train_dir = os.path.join(category_dir, \"train\")\n",
    "    test_dir = os.path.join(category_dir, \"test\")\n",
    "    \n",
    "    print(f\"\\nExploring category: {CATEGORY}\")\n",
    "    \n",
    "    # Training data\n",
    "    if os.path.exists(train_dir):\n",
    "        train_subfolders = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "        print(f\"Training subfolders: {train_subfolders}\")\n",
    "        \n",
    "        # Count training samples\n",
    "        for subfolder in train_subfolders:\n",
    "            subfolder_path = os.path.join(train_dir, subfolder)\n",
    "            num_samples = len([f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))])\n",
    "            print(f\"  - {subfolder}: {num_samples} samples\")\n",
    "    \n",
    "    # Test data\n",
    "    if os.path.exists(test_dir):\n",
    "        test_subfolders = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
    "        print(f\"\\nTest subfolders: {test_subfolders}\")\n",
    "        \n",
    "        # Count test samples\n",
    "        for subfolder in test_subfolders:\n",
    "            subfolder_path = os.path.join(test_dir, subfolder)\n",
    "            num_samples = len([f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))])\n",
    "            print(f\"  - {subfolder}: {num_samples} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def show_examples(category, defect_types=None, num_examples=3):\n",
    "    \"\"\"\n",
    "    Display example images from the dataset\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5 * (len(defect_types) + 1)))\n",
    "    \n",
    "    # First show normal examples\n",
    "    normal_dir = os.path.join(BASE_DIR, category, \"train\", \"good\")\n",
    "    normal_files = glob.glob(os.path.join(normal_dir, \"*.png\"))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        if i < len(normal_files):\n",
    "            img_path = normal_files[i]\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.subplot(len(defect_types) + 1, num_examples, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Normal\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    # Then show defect examples\n",
    "    for j, defect_type in enumerate(defect_types):\n",
    "        defect_dir = os.path.join(BASE_DIR, category, \"test\", defect_type)\n",
    "        defect_files = glob.glob(os.path.join(defect_dir, \"*.png\"))\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            if i < len(defect_files):\n",
    "                img_path = defect_files[i]\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:  # Check if image was loaded correctly\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    plt.subplot(len(defect_types) + 1, num_examples, (j + 1) * num_examples + i + 1)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f\"{defect_type}\")\n",
    "                    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('example_images.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explore defect types for the selected category\n",
    "test_dir = os.path.join(BASE_DIR, CATEGORY, \"test\")\n",
    "if os.path.exists(test_dir):\n",
    "    defect_types = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d)) and d != \"good\"]\n",
    "    print(f\"Defect types for {CATEGORY}: {defect_types}\")\n",
    "    \n",
    "    # Show examples of each defect type\n",
    "    show_examples(CATEGORY, defect_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_and_prepare_data(normal_dir, anomaly_dir, img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load and prepare data from normal and anomaly directories\n",
    "    \"\"\"\n",
    "    # Create empty lists for data and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Load normal images (label 0)\n",
    "    normal_files = glob.glob(os.path.join(normal_dir, \"*.png\"))\n",
    "    for img_path in normal_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0  # Normalize\n",
    "        images.append(img)\n",
    "        labels.append(0)  # 0 for normal\n",
    "    \n",
    "    # Load anomaly images (label 1)\n",
    "    anomaly_categories = [d for d in os.listdir(anomaly_dir) if d != \"good\"]\n",
    "    for category in anomaly_categories:\n",
    "        anomaly_files = glob.glob(os.path.join(anomaly_dir, category, \"*.png\"))\n",
    "        for img_path in anomaly_files:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = img / 255.0  # Normalize\n",
    "            images.append(img)\n",
    "            labels.append(1)  # 1 for anomaly\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "NORMAL_DIR = os.path.join(BASE_DIR, CATEGORY, \"train\", \"good\")\n",
    "ANOMALY_DIR = os.path.join(BASE_DIR, CATEGORY, \"test\")\n",
    "\n",
    "# Load and prepare the data\n",
    "X, y = load_and_prepare_data(NORMAL_DIR, ANOMALY_DIR)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"Normal samples: {np.sum(y_train == 0)}\")\n",
    "print(f\"Defect samples: {np.sum(y_train == 1)}\")\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(f\"Normal samples: {np.sum(y_test == 0)}\")\n",
    "print(f\"Defect samples: {np.sum(y_test == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def build_defect_detection_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build a CNN model for defect detection\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification: normal vs anomaly\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create and compile the model\n",
    "model = build_defect_detection_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data augmentation for training\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_test, y_test),\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "
